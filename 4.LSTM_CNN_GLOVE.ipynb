{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TASKPHD_LSTM_CNN_GLOVE_FINAL.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K-YALm3hYaeb",
        "outputId": "da5e6f81-b788-46b9-fe82-34ec10ee30a2"
      },
      "source": [
        "cd /content/drive/MyDrive/tophd/snowman-application-tasks-ay21-22/dataset"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/tophd/snowman-application-tasks-ay21-22/dataset\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_pY_k914aR-i"
      },
      "source": [
        "import pandas as pd\n",
        "df_train = pd.read_csv(\"train.csv\", encoding='cp1252')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OvM636KGaWRU"
      },
      "source": [
        "df_test = pd.read_csv(\"test.csv\",encoding = 'cp1252')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1TNj88NrY3nQ",
        "outputId": "7fdf858a-4864-461d-d456-7a059d131a28"
      },
      "source": [
        "#preprocessing\n",
        "import nltk\n",
        "nltk.download(\"stopwords\")\n",
        "from nltk.corpus import stopwords"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dq9kfH2LanVK"
      },
      "source": [
        "import re\n",
        "def text_preprocessing(s):\n",
        "  #lower\n",
        "  s = str(s).lower()\n",
        "  # Isolate and remove punctuations except '?'\n",
        "  s = re.sub(r'([\\'\\\"\\.\\(\\)\\!\\?\\\\\\/\\,\\^\\*])', r' \\1 ', s)\n",
        "  s = re.sub(r'[^\\w\\s\\?]', ' ', s)\n",
        "  # Remove some special characters\n",
        "  s = re.sub(r'([\\;\\:\\|•«\\n])', ' ', s)\n",
        "  s = re.sub(r'[^a-zA-z0-9\\s]', '', s)\n",
        "  # Remove number\n",
        "  s = re.sub('[0-9]{5,}', '#####', s)\n",
        "  s = re.sub('[0-9]{4}', '####', s)\n",
        "  s = re.sub('[0-9]{3}', '###', s)\n",
        "  s = re.sub('[0-9]{2}', '##', s)\n",
        "  # Remove trailing whitespace\n",
        "  s = re.sub(r'\\s+', ' ', s).strip()\n",
        "\n",
        "  return s"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8KE55vsKazGA"
      },
      "source": [
        "train = df_train\n",
        "test = df_test"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8INBPLmpbENd"
      },
      "source": [
        "train['Tweets'] = train['Tweets'].apply(text_preprocessing)\n",
        "test['Tweets'] = test['Tweets'].apply(text_preprocessing) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xut6kJfccnZv"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_val, y_train, y_val = train_test_split(train['Tweets'], train['Label'],\n",
        "                                                    stratify=train['Label'], \n",
        "                                                    test_size=0.1, random_state = 24)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4UbwkVyCdAYR"
      },
      "source": [
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "## Tokenize the sentences\n",
        "tokenizer = Tokenizer(num_words=20000) #unique word to use\n",
        "tokenizer.fit_on_texts(list(X_train))\n",
        "X_train = tokenizer.texts_to_sequences(X_train)\n",
        "X_val = tokenizer.texts_to_sequences(X_val)\n",
        "\n",
        "## Pad the sentences \n",
        "X_train = pad_sequences(X_train, maxlen=64) #max num of word in text\n",
        "X_val = pad_sequences(X_val, maxlen=64)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0nhBOl9PYe7v"
      },
      "source": [
        "#Encode Label\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "le = LabelEncoder()\n",
        "y_train = le.fit_transform(y_train.values)\n",
        "y_val = le.transform(y_val.values)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NZDYDCB8Ye-k",
        "outputId": "6969284b-8a61-4b3a-f075-044927669ef5"
      },
      "source": [
        "le.classes_"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['none', 'racism', 'sexism'], dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dKlWb6Lbkkwl"
      },
      "source": [
        "## FUNCTIONS TAKEN FROM https://www.kaggle.com/gmhost/gru-capsule\n",
        "import numpy as np\n",
        "max_features = 20000\n",
        "def load_glove(word_index):\n",
        "    EMBEDDING_FILE = './glove.840B.300d.txt'\n",
        "    def get_coefs(word,*arr): return word, np.asarray(arr, dtype='float32')[:300]\n",
        "    embeddings_index = dict(get_coefs(*o.split(\" \")) for o in open(EMBEDDING_FILE))\n",
        "    \n",
        "    all_embs = np.stack(embeddings_index.values())\n",
        "    emb_mean,emb_std = -0.005838499,0.48782197\n",
        "    embed_size = all_embs.shape[1]\n",
        "\n",
        "    nb_words = min(max_features, len(word_index)+1)\n",
        "    embedding_matrix = np.random.normal(emb_mean, emb_std, (nb_words, embed_size))\n",
        "    for word, i in word_index.items():\n",
        "        if i >= max_features: continue\n",
        "        embedding_vector = embeddings_index.get(word)\n",
        "        if embedding_vector is not None: \n",
        "            embedding_matrix[i] = embedding_vector\n",
        "        else:\n",
        "            embedding_vector = embeddings_index.get(word.capitalize())\n",
        "            if embedding_vector is not None: \n",
        "                embedding_matrix[i] = embedding_vector\n",
        "    return embedding_matrix"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-RZE7ECiksYE",
        "outputId": "2c7967a8-6df4-4e46-dee1-86dc296891ac"
      },
      "source": [
        "#load glove\n",
        "embedding_matrix = load_glove(tokenizer.word_index)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py:2882: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n",
            "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9ThvuAq6loDq"
      },
      "source": [
        "**CNN Model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kh0v13GOlltz"
      },
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "embed_size = 300 # size of each word vector\n",
        "class CNN_Classifier(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(CNN_Classifier, self).__init__()\n",
        "    filter_sizes = [1,2,3,5]\n",
        "    num_filters = 36\n",
        "    n_classes = len(le.classes_)\n",
        "    self.embedding = nn.Embedding(max_features, embed_size)\n",
        "    self.embedding.weight = nn.Parameter(torch.tensor(embedding_matrix, dtype=torch.float32))\n",
        "    self.embedding.weight.requires_grad = False\n",
        "    self.convs1 = nn.ModuleList([nn.Conv2d(1, num_filters, (K, embed_size)) for K in filter_sizes])\n",
        "    self.dropout = nn.Dropout(0.1)\n",
        "    self.fc1 = nn.Linear(len(filter_sizes)*num_filters, n_classes)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.embedding(x)  \n",
        "    x = x.unsqueeze(1)  \n",
        "    x = [F.relu(conv(x)).squeeze(3) for conv in self.convs1] \n",
        "    x = [F.max_pool1d(i, i.size(2)).squeeze(2) for i in x]  \n",
        "    x = torch.cat(x, 1)\n",
        "    x = self.dropout(x)  \n",
        "    logit = self.fc1(x) \n",
        "    return logit"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4OqGs4Uxm9Xq",
        "outputId": "f8ada4a1-dcdc-467c-b290-c38b3adc2f68"
      },
      "source": [
        "import torch\n",
        "#train on CPU\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "print(device) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cKuwyndtnd85",
        "outputId": "f704283c-0751-48de-8492-8397980e37f4"
      },
      "source": [
        "#call model\n",
        "model = CNN_Classifier()\n",
        "model.to(device)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CNN_Classifier(\n",
              "  (embedding): Embedding(20000, 300)\n",
              "  (convs1): ModuleList(\n",
              "    (0): Conv2d(1, 36, kernel_size=(1, 300), stride=(1, 1))\n",
              "    (1): Conv2d(1, 36, kernel_size=(2, 300), stride=(1, 1))\n",
              "    (2): Conv2d(1, 36, kernel_size=(3, 300), stride=(1, 1))\n",
              "    (3): Conv2d(1, 36, kernel_size=(5, 300), stride=(1, 1))\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (fc1): Linear(in_features=144, out_features=3, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c9T9j9YHnQ2b"
      },
      "source": [
        "#loss function and optimizer\n",
        "loss_fn = nn.CrossEntropyLoss(reduction='sum')\n",
        "optimizer = torch.optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=1e-3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wCsenYk5n7tr"
      },
      "source": [
        "#convert data to tensor\n",
        "X_train = torch.tensor(X_train, dtype = torch.long)\n",
        "y_train = torch.tensor(y_train, dtype = torch.long)\n",
        "X_valid = torch.tensor(X_val, dtype = torch.long)\n",
        "y_valid = torch.tensor(y_val, dtype = torch.long)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gXCwZBijojMB"
      },
      "source": [
        "#move to cuda\n",
        "X_train = X_train.to(device)\n",
        "y_train = y_train.to(device)\n",
        "X_valid = X_valid.to(device)\n",
        "y_valid = y_valid.to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p6iER1OrouNZ"
      },
      "source": [
        "#create dataset\n",
        "train_dataset = torch.utils.data.TensorDataset(X_train, y_train)\n",
        "val_dataset = torch.utils.data.TensorDataset(X_valid, y_valid)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XEbhEuPmo5oL"
      },
      "source": [
        "#create dataloader\n",
        "batch_size = 512\n",
        "train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size= batch_size, shuffle=True)\n",
        "val_dataloader = torch.utils.data.DataLoader(val_dataset, batch_size= batch_size, shuffle=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dmclsEjena4A",
        "outputId": "2d93eae5-84d4-4dd8-99f0-c9496925c244"
      },
      "source": [
        "import time\n",
        "\n",
        "n_epochs = 5\n",
        "train_loss = []\n",
        "valid_loss = []\n",
        "\n",
        "for epoch in range(n_epochs):\n",
        "  start_time = time.time()\n",
        "  # model to train\n",
        "  model.train()\n",
        "  avg_loss = 0.  \n",
        "  for i, (x_batch, y_batch) in enumerate(train_dataloader):\n",
        "    # Predict\n",
        "    y_pred = model(x_batch)\n",
        "    # Compute loss\n",
        "    loss = loss_fn(y_pred, y_batch)\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    avg_loss += loss.item() / len(train_dataloader)\n",
        "    \n",
        "  # Set model to validation configuration \n",
        "  model.eval()        \n",
        "  avg_val_loss = 0.\n",
        "  val_preds = np.zeros((len(X_val),len(le.classes_)))\n",
        "    \n",
        "  for i, (x_batch, y_batch) in enumerate(val_dataloader):\n",
        "    y_pred = model(x_batch).detach()\n",
        "    avg_val_loss += loss_fn(y_pred, y_batch).item() / len(val_dataloader)\n",
        "    # store predictions\n",
        "    val_preds[i * batch_size:(i+1) * batch_size] =F.softmax(y_pred).cpu().numpy()\n",
        "    \n",
        "  # Check Accuracy\n",
        "  val_accuracy = sum(val_preds.argmax(axis=1)==y_val)/len(y_val)\n",
        "  train_loss.append(avg_loss)\n",
        "  valid_loss.append(avg_val_loss)\n",
        "  elapsed_time = time.time() - start_time \n",
        "  print('Epoch {} \\t loss={:.2f} \\t val_loss={:.2f}  \\t val_acc={:.2f}'.format(epoch + 1, avg_loss, avg_val_loss, val_accuracy))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:31: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1 \t loss=342.77 \t val_loss=225.72  \t val_acc=0.78\n",
            "Epoch 2 \t loss=231.25 \t val_loss=203.87  \t val_acc=0.80\n",
            "Epoch 3 \t loss=200.71 \t val_loss=184.16  \t val_acc=0.82\n",
            "Epoch 4 \t loss=181.90 \t val_loss=179.49  \t val_acc=0.83\n",
            "Epoch 5 \t loss=164.73 \t val_loss=171.56  \t val_acc=0.84\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aRT7w4T-siUQ"
      },
      "source": [
        "torch.save(model,'CNN_Classifier.pt')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rpxKmgyMzYFS"
      },
      "source": [
        "#predict\n",
        "\n",
        "def predict(x):    \n",
        "    # tokenize\n",
        "    x = tokenizer.texts_to_sequences([x])\n",
        "    # pad\n",
        "    x = pad_sequences(x, maxlen=64)\n",
        "    # create dataset\n",
        "    x = torch.tensor(x, dtype=torch.long).to(device)\n",
        "\n",
        "    pred = model(x).detach()\n",
        "    pred = F.softmax(pred).cpu().numpy()\n",
        "\n",
        "    pred = pred.argmax(axis=1)\n",
        "\n",
        "    pred = le.classes_[pred]\n",
        "    return pred[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AC6z8W-8zpuq",
        "outputId": "42615d78-f8d8-4c65-9fdc-431f7c789d5f"
      },
      "source": [
        "y_CNN_pred = []\n",
        "for sent in test.Tweets.values:\n",
        "  pred = predict(sent)\n",
        "  y_CNN_pred.append(pred)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:12: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  if sys.path[0] == '':\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n8iVdmub0Nwb"
      },
      "source": [
        "y_true = df_test['Label']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aEAW4yrq0YaA",
        "outputId": "a9d72262-2d0e-4dd2-b49f-82d923ffcaf8"
      },
      "source": [
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(y_true, y_CNN_pred))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "        none       0.76      0.98      0.86      2186\n",
            "      racism       1.00      0.62      0.77       387\n",
            "      sexism       0.69      0.18      0.29       633\n",
            "\n",
            "    accuracy                           0.78      3206\n",
            "   macro avg       0.82      0.59      0.64      3206\n",
            "weighted avg       0.78      0.78      0.73      3206\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tRT2pdge046k"
      },
      "source": [
        "**LSTM Model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6fxA77I30yPR"
      },
      "source": [
        "class BiLSTM_Classifier(nn.Module):    \n",
        "  def __init__(self):\n",
        "    super(BiLSTM_Classifier, self).__init__()\n",
        "    self.hidden_size = 64\n",
        "    drp = 0.1 #dropout\n",
        "    n_classes = len(le.classes_)\n",
        "    self.embedding = nn.Embedding(max_features, embed_size)\n",
        "    self.embedding.weight = nn.Parameter(torch.tensor(embedding_matrix, dtype=torch.float32))\n",
        "    self.embedding.weight.requires_grad = False\n",
        "    self.lstm = nn.LSTM(embed_size, self.hidden_size, bidirectional=True, batch_first=True)\n",
        "    self.linear = nn.Linear(self.hidden_size*4 , 64)\n",
        "    self.relu = nn.ReLU()\n",
        "    self.dropout = nn.Dropout(drp)\n",
        "    self.out = nn.Linear(64, n_classes)\n",
        "\n",
        "  def forward(self, x):\n",
        "    h_embedding = self.embedding(x)\n",
        "    #_embedding = torch.squeeze(torch.unsqueeze(h_embedding, 0))\n",
        "    h_lstm, _ = self.lstm(h_embedding)\n",
        "    avg_pool = torch.mean(h_lstm, 1)\n",
        "    max_pool, _ = torch.max(h_lstm, 1)\n",
        "    conc = torch.cat(( avg_pool, max_pool), 1)\n",
        "    conc = self.relu(self.linear(conc))\n",
        "    conc = self.dropout(conc)\n",
        "    out = self.out(conc)\n",
        "    return out"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pb7jYUTC1h2T",
        "outputId": "a57936ce-cf57-4c2a-a57b-eabd156e6e3f"
      },
      "source": [
        "#call BiLSTM Classifier\n",
        "model = BiLSTM_Classifier()\n",
        "loss_fn = nn.CrossEntropyLoss(reduction='sum')\n",
        "optimizer = torch.optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=1e-3)\n",
        "model.to(device)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BiLSTM_Classifier(\n",
              "  (embedding): Embedding(20000, 300)\n",
              "  (lstm): LSTM(300, 64, batch_first=True, bidirectional=True)\n",
              "  (linear): Linear(in_features=256, out_features=64, bias=True)\n",
              "  (relu): ReLU()\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (out): Linear(in_features=64, out_features=3, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DyVrhgm1zsmI",
        "outputId": "de90cac9-0bcb-4937-bb2e-ed574f9b5000"
      },
      "source": [
        "n_epochs = 10\n",
        "train_loss = []\n",
        "valid_loss = []\n",
        "\n",
        "for epoch in range(n_epochs):\n",
        "  # Set model to train \n",
        "  model.train()\n",
        "  avg_loss = 0.  \n",
        "  for i, (x_batch, y_batch) in enumerate(train_dataloader):\n",
        "    # Predict\n",
        "    y_pred = model(x_batch)\n",
        "    # Compute loss\n",
        "    loss = loss_fn(y_pred, y_batch)\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    avg_loss += loss.item() / len(train_dataloader)\n",
        "    \n",
        "  # Set model to validation configuration \n",
        "  model.eval()        \n",
        "  avg_val_loss = 0.\n",
        "  val_preds = np.zeros((len(X_val),len(le.classes_)))\n",
        "    \n",
        "  for i, (x_batch, y_batch) in enumerate(val_dataloader):\n",
        "    y_pred = model(x_batch).detach()\n",
        "    avg_val_loss += loss_fn(y_pred, y_batch).item() / len(val_dataloader)\n",
        "    # store predictions\n",
        "    val_preds[i * batch_size:(i+1) * batch_size] =F.softmax(y_pred).cpu().numpy()\n",
        "    \n",
        "  # Check Accuracy\n",
        "  val_accuracy = sum(val_preds.argmax(axis=1)==y_val)/len(y_val)\n",
        "  train_loss.append(avg_loss)\n",
        "  valid_loss.append(avg_val_loss)\n",
        "  print('Epoch {} \\t loss={:.2f} \\t val_loss={:.2f}  \\t val_acc={:.2f}'.format(epoch + 1, avg_loss, avg_val_loss, val_accuracy))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:28: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1 \t loss=436.72 \t val_loss=349.30  \t val_acc=0.68\n",
            "Epoch 2 \t loss=392.77 \t val_loss=308.08  \t val_acc=0.68\n",
            "Epoch 3 \t loss=304.67 \t val_loss=233.01  \t val_acc=0.78\n",
            "Epoch 4 \t loss=233.05 \t val_loss=199.82  \t val_acc=0.81\n",
            "Epoch 5 \t loss=203.55 \t val_loss=189.96  \t val_acc=0.82\n",
            "Epoch 6 \t loss=184.70 \t val_loss=178.99  \t val_acc=0.82\n",
            "Epoch 7 \t loss=167.72 \t val_loss=174.72  \t val_acc=0.83\n",
            "Epoch 8 \t loss=153.17 \t val_loss=173.39  \t val_acc=0.84\n",
            "Epoch 9 \t loss=140.82 \t val_loss=177.06  \t val_acc=0.84\n",
            "Epoch 10 \t loss=135.06 \t val_loss=164.93  \t val_acc=0.85\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6fbJ5brF8Xmb"
      },
      "source": [
        "#save model\n",
        "torch.save(model,'LSTM_Classifier.pt')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9tZ9rcG96si2"
      },
      "source": [
        "#predict\n",
        "def predict(x):    \n",
        "    # tokenize\n",
        "    x = tokenizer.texts_to_sequences([x])\n",
        "    # pad\n",
        "    x = pad_sequences(x, maxlen=64)\n",
        "    # create dataset\n",
        "    x = torch.tensor(x, dtype=torch.long).to(device)\n",
        "\n",
        "    pred = model(x).detach()\n",
        "    pred = F.softmax(pred).cpu().numpy()\n",
        "\n",
        "    pred = pred.argmax(axis=1)\n",
        "\n",
        "    pred = le.classes_[pred]\n",
        "    return pred[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Vb6gqO8m6sy",
        "outputId": "1af38dec-7167-448b-8113-4354cb8e0bf4"
      },
      "source": [
        "y_LSTM_pred = []\n",
        "for sent in test.Tweets.values:\n",
        "  pred = predict(sent)\n",
        "  y_LSTM_pred.append(pred)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:11: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  # This is added back by InteractiveShellApp.init_path()\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "caDUbUgEkx5s",
        "outputId": "15533e55-d21b-43dc-8af3-501550737cc2"
      },
      "source": [
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(y_true, y_LSTM_pred))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "        none       0.80      0.93      0.86      2186\n",
            "      racism       1.00      0.62      0.76       387\n",
            "      sexism       0.64      0.42      0.51       633\n",
            "\n",
            "    accuracy                           0.79      3206\n",
            "   macro avg       0.81      0.66      0.71      3206\n",
            "weighted avg       0.79      0.79      0.78      3206\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sbCpolfEYfBp"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FL-XBY7gYfEF"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TgMpdtB1YfGy"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CWXuNlscYfJi"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MLIwv2zPYfMn"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kL9ingBnYfP1"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}