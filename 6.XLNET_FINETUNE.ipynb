{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TASKPHD_XLNET_FINETUNE.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "432eb588d39543ed9d918c6d22150097": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_ca66308cb5944c09a6802e8bee3094a4",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_4fc7cc2e1c824e3c9f8ab4978ee539dd",
              "IPY_MODEL_044d0440c0ba45478d1cade443dc23bf"
            ]
          }
        },
        "ca66308cb5944c09a6802e8bee3094a4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "4fc7cc2e1c824e3c9f8ab4978ee539dd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_08a8a1828b7b418e92ded38da95173b2",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 760,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 760,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_dd4c5e7dbdf649edafed74378d865989"
          }
        },
        "044d0440c0ba45478d1cade443dc23bf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_cdf72d63b8da4c9987458dd28b78f77f",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 760/760 [00:00&lt;00:00, 1.50kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_3ea2d5a5ea0f4a82ace32c869698164c"
          }
        },
        "08a8a1828b7b418e92ded38da95173b2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "dd4c5e7dbdf649edafed74378d865989": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "cdf72d63b8da4c9987458dd28b78f77f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "3ea2d5a5ea0f4a82ace32c869698164c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c933eab1b19b469aa3717517ab7bb874": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_51de639f8f0a4656bbc55c08c4477487",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_73575105f85e4e6ebb4b44be450777b4",
              "IPY_MODEL_55694323346b48a79a12253a5fc0f640"
            ]
          }
        },
        "51de639f8f0a4656bbc55c08c4477487": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "73575105f85e4e6ebb4b44be450777b4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_78c4f7065c1647948c304f197b5ae401",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 467042463,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 467042463,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_e3ffdec4db0f45c8b867f2ce8d84276a"
          }
        },
        "55694323346b48a79a12253a5fc0f640": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_34b6e588a3c747ea8cf01584157c1e6d",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 467M/467M [00:07&lt;00:00, 62.1MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_34a8e13163534573a87e34b79c855f25"
          }
        },
        "78c4f7065c1647948c304f197b5ae401": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "e3ffdec4db0f45c8b867f2ce8d84276a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "34b6e588a3c747ea8cf01584157c1e6d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "34a8e13163534573a87e34b79c855f25": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0zuBWlZqY0NJ",
        "outputId": "f0c0bcee-263e-49e8-99f7-5cf584b583c3"
      },
      "source": [
        "cd /content/drive/MyDrive/tophd/snowman-application-tasks-ay21-22/dataset"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/tophd/snowman-application-tasks-ay21-22/dataset\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XoznEpaPY__e"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "train = pd.read_csv(\"train.csv\", encoding='cp1252')\n",
        "test = pd.read_csv(\"test.csv\",encoding = 'cp1252')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cOR_BfqGZ4at",
        "outputId": "04b1f29a-4908-4ae4-c825-79179b6b4155"
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3a/83/e74092e7f24a08d751aa59b37a9fc572b2e4af3918cb66f7766c3affb1b4/transformers-3.5.1-py3-none-any.whl (1.3MB)\n",
            "\r\u001b[K     |▎                               | 10kB 15.1MB/s eta 0:00:01\r\u001b[K     |▌                               | 20kB 20.5MB/s eta 0:00:01\r\u001b[K     |▊                               | 30kB 24.9MB/s eta 0:00:01\r\u001b[K     |█                               | 40kB 23.0MB/s eta 0:00:01\r\u001b[K     |█▎                              | 51kB 16.8MB/s eta 0:00:01\r\u001b[K     |█▌                              | 61kB 18.6MB/s eta 0:00:01\r\u001b[K     |█▊                              | 71kB 13.9MB/s eta 0:00:01\r\u001b[K     |██                              | 81kB 14.1MB/s eta 0:00:01\r\u001b[K     |██▎                             | 92kB 13.4MB/s eta 0:00:01\r\u001b[K     |██▌                             | 102kB 12.4MB/s eta 0:00:01\r\u001b[K     |██▊                             | 112kB 12.4MB/s eta 0:00:01\r\u001b[K     |███                             | 122kB 12.4MB/s eta 0:00:01\r\u001b[K     |███▎                            | 133kB 12.4MB/s eta 0:00:01\r\u001b[K     |███▌                            | 143kB 12.4MB/s eta 0:00:01\r\u001b[K     |███▉                            | 153kB 12.4MB/s eta 0:00:01\r\u001b[K     |████                            | 163kB 12.4MB/s eta 0:00:01\r\u001b[K     |████▎                           | 174kB 12.4MB/s eta 0:00:01\r\u001b[K     |████▌                           | 184kB 12.4MB/s eta 0:00:01\r\u001b[K     |████▉                           | 194kB 12.4MB/s eta 0:00:01\r\u001b[K     |█████                           | 204kB 12.4MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 215kB 12.4MB/s eta 0:00:01\r\u001b[K     |█████▌                          | 225kB 12.4MB/s eta 0:00:01\r\u001b[K     |█████▉                          | 235kB 12.4MB/s eta 0:00:01\r\u001b[K     |██████                          | 245kB 12.4MB/s eta 0:00:01\r\u001b[K     |██████▎                         | 256kB 12.4MB/s eta 0:00:01\r\u001b[K     |██████▌                         | 266kB 12.4MB/s eta 0:00:01\r\u001b[K     |██████▉                         | 276kB 12.4MB/s eta 0:00:01\r\u001b[K     |███████                         | 286kB 12.4MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 296kB 12.4MB/s eta 0:00:01\r\u001b[K     |███████▋                        | 307kB 12.4MB/s eta 0:00:01\r\u001b[K     |███████▉                        | 317kB 12.4MB/s eta 0:00:01\r\u001b[K     |████████                        | 327kB 12.4MB/s eta 0:00:01\r\u001b[K     |████████▎                       | 337kB 12.4MB/s eta 0:00:01\r\u001b[K     |████████▋                       | 348kB 12.4MB/s eta 0:00:01\r\u001b[K     |████████▉                       | 358kB 12.4MB/s eta 0:00:01\r\u001b[K     |█████████                       | 368kB 12.4MB/s eta 0:00:01\r\u001b[K     |█████████▎                      | 378kB 12.4MB/s eta 0:00:01\r\u001b[K     |█████████▋                      | 389kB 12.4MB/s eta 0:00:01\r\u001b[K     |█████████▉                      | 399kB 12.4MB/s eta 0:00:01\r\u001b[K     |██████████                      | 409kB 12.4MB/s eta 0:00:01\r\u001b[K     |██████████▎                     | 419kB 12.4MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 430kB 12.4MB/s eta 0:00:01\r\u001b[K     |██████████▉                     | 440kB 12.4MB/s eta 0:00:01\r\u001b[K     |███████████                     | 450kB 12.4MB/s eta 0:00:01\r\u001b[K     |███████████▍                    | 460kB 12.4MB/s eta 0:00:01\r\u001b[K     |███████████▋                    | 471kB 12.4MB/s eta 0:00:01\r\u001b[K     |███████████▉                    | 481kB 12.4MB/s eta 0:00:01\r\u001b[K     |████████████                    | 491kB 12.4MB/s eta 0:00:01\r\u001b[K     |████████████▍                   | 501kB 12.4MB/s eta 0:00:01\r\u001b[K     |████████████▋                   | 512kB 12.4MB/s eta 0:00:01\r\u001b[K     |████████████▉                   | 522kB 12.4MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 532kB 12.4MB/s eta 0:00:01\r\u001b[K     |█████████████▍                  | 542kB 12.4MB/s eta 0:00:01\r\u001b[K     |█████████████▋                  | 552kB 12.4MB/s eta 0:00:01\r\u001b[K     |█████████████▉                  | 563kB 12.4MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 573kB 12.4MB/s eta 0:00:01\r\u001b[K     |██████████████▍                 | 583kB 12.4MB/s eta 0:00:01\r\u001b[K     |██████████████▋                 | 593kB 12.4MB/s eta 0:00:01\r\u001b[K     |██████████████▉                 | 604kB 12.4MB/s eta 0:00:01\r\u001b[K     |███████████████▏                | 614kB 12.4MB/s eta 0:00:01\r\u001b[K     |███████████████▍                | 624kB 12.4MB/s eta 0:00:01\r\u001b[K     |███████████████▋                | 634kB 12.4MB/s eta 0:00:01\r\u001b[K     |███████████████▉                | 645kB 12.4MB/s eta 0:00:01\r\u001b[K     |████████████████▏               | 655kB 12.4MB/s eta 0:00:01\r\u001b[K     |████████████████▍               | 665kB 12.4MB/s eta 0:00:01\r\u001b[K     |████████████████▋               | 675kB 12.4MB/s eta 0:00:01\r\u001b[K     |████████████████▉               | 686kB 12.4MB/s eta 0:00:01\r\u001b[K     |█████████████████▏              | 696kB 12.4MB/s eta 0:00:01\r\u001b[K     |█████████████████▍              | 706kB 12.4MB/s eta 0:00:01\r\u001b[K     |█████████████████▋              | 716kB 12.4MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 727kB 12.4MB/s eta 0:00:01\r\u001b[K     |██████████████████▏             | 737kB 12.4MB/s eta 0:00:01\r\u001b[K     |██████████████████▍             | 747kB 12.4MB/s eta 0:00:01\r\u001b[K     |██████████████████▋             | 757kB 12.4MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 768kB 12.4MB/s eta 0:00:01\r\u001b[K     |███████████████████▏            | 778kB 12.4MB/s eta 0:00:01\r\u001b[K     |███████████████████▍            | 788kB 12.4MB/s eta 0:00:01\r\u001b[K     |███████████████████▋            | 798kB 12.4MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 808kB 12.4MB/s eta 0:00:01\r\u001b[K     |████████████████████▏           | 819kB 12.4MB/s eta 0:00:01\r\u001b[K     |████████████████████▍           | 829kB 12.4MB/s eta 0:00:01\r\u001b[K     |████████████████████▋           | 839kB 12.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 849kB 12.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████▏          | 860kB 12.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████▍          | 870kB 12.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████▊          | 880kB 12.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 890kB 12.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████▏         | 901kB 12.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████▍         | 911kB 12.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████▊         | 921kB 12.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 931kB 12.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████▏        | 942kB 12.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████▍        | 952kB 12.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████▊        | 962kB 12.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 972kB 12.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████▏       | 983kB 12.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████▍       | 993kB 12.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████▊       | 1.0MB 12.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 1.0MB 12.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▏      | 1.0MB 12.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▌      | 1.0MB 12.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▊      | 1.0MB 12.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 1.1MB 12.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 1.1MB 12.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▌     | 1.1MB 12.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▊     | 1.1MB 12.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 1.1MB 12.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▏    | 1.1MB 12.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▌    | 1.1MB 12.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▊    | 1.1MB 12.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 1.1MB 12.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▏   | 1.1MB 12.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▌   | 1.2MB 12.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▊   | 1.2MB 12.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 1.2MB 12.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▎  | 1.2MB 12.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▌  | 1.2MB 12.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▊  | 1.2MB 12.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 1.2MB 12.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▎ | 1.2MB 12.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▌ | 1.2MB 12.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▊ | 1.2MB 12.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 1.3MB 12.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▎| 1.3MB 12.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▌| 1.3MB 12.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▊| 1.3MB 12.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 1.3MB 12.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 1.3MB 12.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.5)\n",
            "Collecting sentencepiece==0.1.91\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d4/a4/d0a884c4300004a78cca907a6ff9a5e9fe4f090f5d95ab341c53d28cbc58/sentencepiece-0.1.91-cp36-cp36m-manylinux1_x86_64.whl (1.1MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1MB 41.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n",
            "\u001b[K     |████████████████████████████████| 890kB 47.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.8)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.6/dist-packages (from transformers) (3.12.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Collecting tokenizers==0.9.3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/4c/34/b39eb9994bc3c999270b69c9eea40ecc6f0e97991dba28282b9fd32d44ee/tokenizers-0.9.3-cp36-cp36m-manylinux1_x86_64.whl (2.9MB)\n",
            "\u001b[K     |████████████████████████████████| 2.9MB 43.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.11.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.17.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf->transformers) (50.3.2)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893257 sha256=86df49a644e01fcc098256be2c0b5ba7ba0e6843218d60fd7b61a724a06d3aa9\n",
            "  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: sentencepiece, sacremoses, tokenizers, transformers\n",
            "Successfully installed sacremoses-0.0.43 sentencepiece-0.1.91 tokenizers-0.9.3 transformers-3.5.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mYq8AhWKZCs2"
      },
      "source": [
        "from transformers import (XLNetConfig, XLNetForSequenceClassification, XLNetTokenizer)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MrPogR6daApc"
      },
      "source": [
        "import re\n",
        "def text_preprocessing(text):\n",
        "    # Remove '@name'\n",
        "    text = re.sub(r'(@.*?)[\\s]', ' ', text)\n",
        "\n",
        "    # Remove trailing whitespace\n",
        "    text = re.sub(r'\\s+', ' ', text).strip()\n",
        "\n",
        "    return text"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ESC5Ycd8a4-3"
      },
      "source": [
        "train['Tweets'] = train['Tweets'].apply(text_preprocessing)\n",
        "test['Tweets'] = test['Tweets'].apply(text_preprocessing)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "id": "QmPQS_0sbibo",
        "outputId": "9993ef2d-1cce-48a5-9de1-c4e26a1742d5"
      },
      "source": [
        "train.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>Tweets</th>\n",
              "      <th>Label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>7281</td>\n",
              "      <td>The jokes and puns are flying free in this cam...</td>\n",
              "      <td>none</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>7282</td>\n",
              "      <td>#MKR Lets see who the producers think are goin...</td>\n",
              "      <td>none</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>7283</td>\n",
              "      <td>Praying Jac and Shaz do well! They're my faves...</td>\n",
              "      <td>none</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>7284</td>\n",
              "      <td>RT Pete Evans the Paleo Capitalist has had his...</td>\n",
              "      <td>none</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>7285</td>\n",
              "      <td>If Kat and Andre stay tonight I will stop watc...</td>\n",
              "      <td>none</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     id                                             Tweets Label\n",
              "0  7281  The jokes and puns are flying free in this cam...  none\n",
              "1  7282  #MKR Lets see who the producers think are goin...  none\n",
              "2  7283  Praying Jac and Shaz do well! They're my faves...  none\n",
              "3  7284  RT Pete Evans the Paleo Capitalist has had his...  none\n",
              "4  7285  If Kat and Andre stay tonight I will stop watc...  none"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aBnaJHDiY71m"
      },
      "source": [
        "# Set a dict for mapping id to tag name\n",
        "# 0:'none', 1:'racism', 2:'sexism\n",
        "tag2idx={'none': 0,'racism': 1,'sexism':2}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CG69yay35GwD"
      },
      "source": [
        "# Mapping index to name\n",
        "tag2name={tag2idx[key] : key for key in tag2idx.keys()}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DOaFlNcb5JfA",
        "outputId": "827d2da9-015d-48be-e9f6-c6cec848c90d"
      },
      "source": [
        "tag2name"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0: 'none', 1: 'racism', 2: 'sexism'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eURhIZtm5LST"
      },
      "source": [
        "import torch\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "n_gpu = torch.cuda.device_count()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BWGLsmlf5OUr",
        "outputId": "40f22792-71c9-4aee-dc17-cd3ff5c502d5"
      },
      "source": [
        "!wget https://s3.amazonaws.com/models.huggingface.co/bert/xlnet-base-cased-spiece.model"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-11-29 16:45:52--  https://s3.amazonaws.com/models.huggingface.co/bert/xlnet-base-cased-spiece.model\n",
            "Resolving s3.amazonaws.com (s3.amazonaws.com)... 52.216.230.181\n",
            "Connecting to s3.amazonaws.com (s3.amazonaws.com)|52.216.230.181|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 798011 (779K) [binary/octet-stream]\n",
            "Saving to: ‘xlnet-base-cased-spiece.model’\n",
            "\n",
            "xlnet-base-cased-sp 100%[===================>] 779.31K  1.77MB/s    in 0.4s    \n",
            "\n",
            "2020-11-29 16:45:53 (1.77 MB/s) - ‘xlnet-base-cased-spiece.model’ saved [798011/798011]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4c_CrnJO5X7m"
      },
      "source": [
        "vocabulary = './xlnet-base-cased-spiece.model'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EZfljTKn5djy"
      },
      "source": [
        "# See model's 'max_position_embeddings' = 512\n",
        "max_len  = 64 "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6gWc3UuA5lYT"
      },
      "source": [
        "# With cased model, set do_lower_case = False\n",
        "tokenizer = XLNetTokenizer(vocab_file=vocabulary,do_lower_case=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DGLiUKEx59eh"
      },
      "source": [
        "sentences = train.Tweets.to_list()\n",
        "labels = train.Label.to_list()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aEkTlaA_5nb3"
      },
      "source": [
        "#input_ids, input_mask, segment_ids\n",
        "full_input_ids = []\n",
        "full_input_masks = []\n",
        "full_segment_ids = []\n",
        "\n",
        "SEG_ID_A   = 0\n",
        "SEG_ID_B   = 1\n",
        "SEG_ID_CLS = 2\n",
        "SEG_ID_SEP = 3\n",
        "SEG_ID_PAD = 4\n",
        "\n",
        "UNK_ID = tokenizer.encode(\"<unk>\")[0]\n",
        "CLS_ID = tokenizer.encode(\"<cls>\")[0]\n",
        "SEP_ID = tokenizer.encode(\"<sep>\")[0]\n",
        "MASK_ID = tokenizer.encode(\"<mask>\")[0]\n",
        "EOD_ID = tokenizer.encode(\"<eod>\")[0]\n",
        "\n",
        "for i,sentence in enumerate(sentences):\n",
        "    # Tokenize sentence to token id list\n",
        "    tokens_a = tokenizer.encode(sentence)\n",
        "    \n",
        "    # Trim the len of text\n",
        "    if(len(tokens_a)>max_len-2):\n",
        "        tokens_a = tokens_a[:max_len-2]\n",
        "        \n",
        "        \n",
        "    tokens = []\n",
        "    segment_ids = []\n",
        "    \n",
        "    for token in tokens_a:\n",
        "        tokens.append(token)\n",
        "        segment_ids.append(SEG_ID_A)\n",
        "        \n",
        "    # Add <sep> token \n",
        "    tokens.append(SEP_ID)\n",
        "    segment_ids.append(SEG_ID_A)\n",
        "    \n",
        "    \n",
        "    # Add <cls> token\n",
        "    tokens.append(CLS_ID)\n",
        "    segment_ids.append(SEG_ID_CLS)\n",
        "    \n",
        "    input_ids = tokens\n",
        "    \n",
        "    # The mask has 0 for real tokens and 1 for padding tokens. Only real\n",
        "    # tokens are attended to.\n",
        "    input_mask = [0] * len(input_ids)\n",
        "\n",
        "    # Zero-pad up to the sequence length at fornt\n",
        "    if len(input_ids) < max_len:\n",
        "        delta_len = max_len - len(input_ids)\n",
        "        input_ids = [0] * delta_len + input_ids\n",
        "        input_mask = [1] * delta_len + input_mask\n",
        "        segment_ids = [SEG_ID_PAD] * delta_len + segment_ids\n",
        "\n",
        "    assert len(input_ids) == max_len\n",
        "    assert len(input_mask) == max_len\n",
        "    assert len(segment_ids) == max_len\n",
        "    \n",
        "    full_input_ids.append(input_ids)\n",
        "    full_input_masks.append(input_mask)\n",
        "    full_segment_ids.append(segment_ids)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qmZ7wttu6N1F"
      },
      "source": [
        "# Make label into id\n",
        "tags = [tag2idx[str(lab)] for lab in labels]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "062R4a7B6pKV"
      },
      "source": [
        "#split train set to train and val\n",
        "from sklearn.model_selection import train_test_split\n",
        "tr_inputs, val_inputs, tr_tags, val_tags,tr_masks, val_masks,tr_segs, val_segs = train_test_split(full_input_ids, tags,full_input_masks,full_segment_ids, \n",
        "                                                            random_state=24, test_size=0.1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z3JnccVi60yW"
      },
      "source": [
        "#convert to tensor\n",
        "tr_inputs = torch.tensor(tr_inputs)\n",
        "val_inputs = torch.tensor(val_inputs)\n",
        "tr_tags = torch.tensor(tr_tags)\n",
        "val_tags = torch.tensor(val_tags)\n",
        "tr_masks = torch.tensor(tr_masks)\n",
        "val_masks = torch.tensor(val_masks)\n",
        "tr_segs = torch.tensor(tr_segs)\n",
        "val_segs = torch.tensor(val_segs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TecT4YNg642x"
      },
      "source": [
        "from torch.utils.data import TensorDataset,RandomSampler,DataLoader,SequentialSampler\n",
        "# Set batch num\n",
        "batch_num = 32\n",
        "# Set token embedding, attention embedding, segment embedding\n",
        "train_data = TensorDataset(tr_inputs, tr_masks,tr_segs, tr_tags)\n",
        "train_sampler = RandomSampler(train_data)\n",
        "# Drop last can make batch training better for the last one\n",
        "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_num,drop_last=True)\n",
        "\n",
        "valid_data = TensorDataset(val_inputs, val_masks,val_segs, val_tags)\n",
        "valid_sampler = SequentialSampler(valid_data)\n",
        "valid_dataloader = DataLoader(valid_data, sampler=valid_sampler, batch_size=batch_num)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BgvuQW2x_HKJ",
        "outputId": "f9ed1d5f-b703-4d2f-f160-20a69990e88c"
      },
      "source": [
        "#download XLNET pretrained\n",
        "!wget https://s3.amazonaws.com/models.huggingface.co/bert/xlnet-base-cased-pytorch_model.bin"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-11-29 17:12:57--  https://s3.amazonaws.com/models.huggingface.co/bert/xlnet-base-cased-pytorch_model.bin\n",
            "Resolving s3.amazonaws.com (s3.amazonaws.com)... 52.217.39.14\n",
            "Connecting to s3.amazonaws.com (s3.amazonaws.com)|52.217.39.14|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 467042463 (445M) [application/octet-stream]\n",
            "Saving to: ‘xlnet-base-cased-pytorch_model.bin’\n",
            "\n",
            "xlnet-base-cased-py 100%[===================>] 445.41M  32.1MB/s    in 16s     \n",
            "\n",
            "2020-11-29 17:13:13 (28.1 MB/s) - ‘xlnet-base-cased-pytorch_model.bin’ saved [467042463/467042463]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SFTFMafK_kmQ",
        "outputId": "230d8e45-90e5-4661-bdde-ce1e37abe181"
      },
      "source": [
        "!wget https://s3.amazonaws.com/models.huggingface.co/bert/xlnet-base-cased-config.json"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-11-29 17:13:20--  https://s3.amazonaws.com/models.huggingface.co/bert/xlnet-base-cased-config.json\n",
            "Resolving s3.amazonaws.com (s3.amazonaws.com)... 52.216.100.109\n",
            "Connecting to s3.amazonaws.com (s3.amazonaws.com)|52.216.100.109|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 760 [application/json]\n",
            "Saving to: ‘xlnet-base-cased-config.json’\n",
            "\n",
            "xlnet-base-cased-co 100%[===================>]     760  --.-KB/s    in 0s      \n",
            "\n",
            "2020-11-29 17:13:21 (16.9 MB/s) - ‘xlnet-base-cased-config.json’ saved [760/760]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 218,
          "referenced_widgets": [
            "432eb588d39543ed9d918c6d22150097",
            "ca66308cb5944c09a6802e8bee3094a4",
            "4fc7cc2e1c824e3c9f8ab4978ee539dd",
            "044d0440c0ba45478d1cade443dc23bf",
            "08a8a1828b7b418e92ded38da95173b2",
            "dd4c5e7dbdf649edafed74378d865989",
            "cdf72d63b8da4c9987458dd28b78f77f",
            "3ea2d5a5ea0f4a82ace32c869698164c",
            "c933eab1b19b469aa3717517ab7bb874",
            "51de639f8f0a4656bbc55c08c4477487",
            "73575105f85e4e6ebb4b44be450777b4",
            "55694323346b48a79a12253a5fc0f640",
            "78c4f7065c1647948c304f197b5ae401",
            "e3ffdec4db0f45c8b867f2ce8d84276a",
            "34b6e588a3c747ea8cf01584157c1e6d",
            "34a8e13163534573a87e34b79c855f25"
          ]
        },
        "id": "5_zVBHq9_qaY",
        "outputId": "b9c63616-db61-4bec-ee0e-06acecb6ed83"
      },
      "source": [
        "# load model\n",
        "model_file_address = \"./\"\n",
        "model = XLNetForSequenceClassification.from_pretrained(\"xlnet-base-cased\",num_labels=len(tag2idx))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "432eb588d39543ed9d918c6d22150097",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=760.0, style=ProgressStyle(description_…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c933eab1b19b469aa3717517ab7bb874",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=467042463.0, style=ProgressStyle(descri…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at xlnet-base-cased were not used when initializing XLNetForSequenceClassification: ['lm_loss.weight', 'lm_loss.bias']\n",
            "- This IS expected if you are initializing XLNetForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing XLNetForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of XLNetForSequenceClassification were not initialized from the model checkpoint at xlnet-base-cased and are newly initialized: ['sequence_summary.summary.weight', 'sequence_summary.summary.bias', 'logits_proj.weight', 'logits_proj.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jCbODAQf_xmU"
      },
      "source": [
        "# load model to cuda\n",
        "model.to(device)\n",
        "# Add multi GPU support\n",
        "if n_gpu >1:\n",
        "    model = torch.nn.DataParallel(model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cCGsLhj0__Oy"
      },
      "source": [
        "# Set epoch and grad max num\n",
        "import math\n",
        "epochs = 5\n",
        "max_grad_norm = 1.0\n",
        "# Cacluate train optimiazaion num\n",
        "num_train_optimization_steps = int( math.ceil(len(tr_inputs) / batch_num) / 1) * epochs\n",
        "# FULL_FINETUNE\n",
        "FULL_FINETUNING = True"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PH2kK-F6AQeg"
      },
      "source": [
        "from torch.optim import Adam\n",
        "if FULL_FINETUNING:\n",
        "    # Fine tune model all layer parameters\n",
        "    param_optimizer = list(model.named_parameters())\n",
        "    no_decay = ['bias', 'gamma', 'beta']\n",
        "    optimizer_grouped_parameters = [\n",
        "        {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)],\n",
        "         'weight_decay_rate': 0.01},\n",
        "        {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)],\n",
        "         'weight_decay_rate': 0.0}\n",
        "    ]\n",
        "else:\n",
        "    # Only fine tune classifier parameters\n",
        "    param_optimizer = list(model.classifier.named_parameters()) \n",
        "    optimizer_grouped_parameters = [{\"params\": [p for n, p in param_optimizer]}]\n",
        "optimizer = Adam(optimizer_grouped_parameters, lr=3e-5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YZUhUDuKATAu",
        "outputId": "b52ca7fc-9dbe-4779-ef43-9bd18f591704"
      },
      "source": [
        "from tqdm import tqdm,trange\n",
        "#training\n",
        "for _ in trange(epochs,desc=\"Epoch\"):\n",
        "  tr_loss = 0\n",
        "  nb_tr_examples, nb_tr_steps = 0, 0\n",
        "  for step, batch in enumerate(train_dataloader):\n",
        "    # add batch to gpu\n",
        "    batch = tuple(t.to(device) for t in batch)\n",
        "    b_input_ids, b_input_mask, b_segs,b_labels = batch\n",
        "        \n",
        "    # forward pass\n",
        "    outputs = model(input_ids =b_input_ids,token_type_ids=b_segs, input_mask = b_input_mask,labels=b_labels)\n",
        "    loss, logits = outputs[:2]\n",
        "    if n_gpu>1:\n",
        "      # When multi gpu, average it\n",
        "      loss = loss.mean()\n",
        "        \n",
        "      # backward pass\n",
        "      loss.backward()\n",
        "        \n",
        "      # track train loss\n",
        "      tr_loss += loss.item()\n",
        "      nb_tr_examples += b_input_ids.size(0)\n",
        "      nb_tr_steps += 1\n",
        "        \n",
        "      # gradient clipping\n",
        "      torch.nn.utils.clip_grad_norm_(parameters=model.parameters(), max_norm=max_grad_norm)\n",
        "        \n",
        "      # update parameters\n",
        "      optimizer.step()\n",
        "      optimizer.zero_grad()\n",
        "        \n",
        "  # print train loss per epoch\n",
        "  print(\"Train loss: {}\".format(tr_loss/nb_tr_steps))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch:  20%|██        | 1/5 [01:01<04:07, 61.83s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train loss: 0.44571096354888545\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\rEpoch:  40%|████      | 2/5 [02:03<03:05, 61.75s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train loss: 0.24756628861650826\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\rEpoch:  60%|██████    | 3/5 [03:04<02:03, 61.66s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train loss: 0.11277336774833707\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\rEpoch:  80%|████████  | 4/5 [04:05<01:01, 61.48s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train loss: 0.06333471307847907\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 100%|██████████| 5/5 [05:06<00:00, 61.34s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train loss: 0.03889558804362928\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CXXRNf-qAnqm",
        "outputId": "01ff41c4-59e9-4773-9d6c-e52e011a95ce"
      },
      "source": [
        "# Save a trained model, configuration and tokenizer\n",
        "xlnet_out_address = './'\n",
        "model_to_save = model.module if hasattr(model, 'module') else model  # Only save the model it-self\n",
        "# If we save using the predefined names, we can load using `from_pretrained`\n",
        "output_model_file = \"./pytorch_model.bin\"\n",
        "output_config_file = \"./config.json\"\n",
        "# Save model into file\n",
        "torch.save(model_to_save.state_dict(), output_model_file)\n",
        "model_to_save.config.to_json_file(output_config_file)\n",
        "tokenizer.save_vocabulary(xlnet_out_address)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('./spiece.model',)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6_7UnR43B6Us",
        "outputId": "958fbc5b-579b-459d-b8f2-a31d457944f0"
      },
      "source": [
        "#evaluate model\n",
        "model = XLNetForSequenceClassification.from_pretrained(xlnet_out_address,num_labels=len(tag2idx))\n",
        "# Set model to GPU\n",
        "model.to(device)\n",
        "if n_gpu >1:\n",
        "    model = torch.nn.DataParallel(model)\n",
        "model.eval()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "XLNetForSequenceClassification(\n",
              "  (transformer): XLNetModel(\n",
              "    (word_embedding): Embedding(32000, 768)\n",
              "    (layer): ModuleList(\n",
              "      (0): XLNetLayer(\n",
              "        (rel_attn): XLNetRelativeAttention(\n",
              "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ff): XLNetFeedForward(\n",
              "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (layer_1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (layer_2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (1): XLNetLayer(\n",
              "        (rel_attn): XLNetRelativeAttention(\n",
              "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ff): XLNetFeedForward(\n",
              "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (layer_1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (layer_2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (2): XLNetLayer(\n",
              "        (rel_attn): XLNetRelativeAttention(\n",
              "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ff): XLNetFeedForward(\n",
              "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (layer_1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (layer_2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (3): XLNetLayer(\n",
              "        (rel_attn): XLNetRelativeAttention(\n",
              "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ff): XLNetFeedForward(\n",
              "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (layer_1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (layer_2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (4): XLNetLayer(\n",
              "        (rel_attn): XLNetRelativeAttention(\n",
              "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ff): XLNetFeedForward(\n",
              "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (layer_1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (layer_2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (5): XLNetLayer(\n",
              "        (rel_attn): XLNetRelativeAttention(\n",
              "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ff): XLNetFeedForward(\n",
              "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (layer_1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (layer_2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (6): XLNetLayer(\n",
              "        (rel_attn): XLNetRelativeAttention(\n",
              "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ff): XLNetFeedForward(\n",
              "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (layer_1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (layer_2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (7): XLNetLayer(\n",
              "        (rel_attn): XLNetRelativeAttention(\n",
              "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ff): XLNetFeedForward(\n",
              "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (layer_1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (layer_2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (8): XLNetLayer(\n",
              "        (rel_attn): XLNetRelativeAttention(\n",
              "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ff): XLNetFeedForward(\n",
              "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (layer_1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (layer_2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (9): XLNetLayer(\n",
              "        (rel_attn): XLNetRelativeAttention(\n",
              "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ff): XLNetFeedForward(\n",
              "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (layer_1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (layer_2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (10): XLNetLayer(\n",
              "        (rel_attn): XLNetRelativeAttention(\n",
              "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ff): XLNetFeedForward(\n",
              "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (layer_1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (layer_2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (11): XLNetLayer(\n",
              "        (rel_attn): XLNetRelativeAttention(\n",
              "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ff): XLNetFeedForward(\n",
              "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (layer_1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (layer_2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "    )\n",
              "    (dropout): Dropout(p=0.1, inplace=False)\n",
              "  )\n",
              "  (sequence_summary): SequenceSummary(\n",
              "    (summary): Linear(in_features=768, out_features=768, bias=True)\n",
              "    (first_dropout): Identity()\n",
              "    (last_dropout): Dropout(p=0.1, inplace=False)\n",
              "  )\n",
              "  (logits_proj): Linear(in_features=768, out_features=3, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PB5eM_QBCMd5"
      },
      "source": [
        "# Set acc funtion\n",
        "def accuracy(out, labels):\n",
        "    outputs = np.argmax(out, axis=1)\n",
        "    return np.sum(outputs == labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xBbe6stCCQ5k"
      },
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "def predict(dataloader):\n",
        "  eval_loss, eval_accuracy = 0, 0\n",
        "  nb_eval_steps, nb_eval_examples = 0, 0\n",
        "\n",
        "  y_true = []\n",
        "  y_predict = []\n",
        "  for step, batch in enumerate(dataloader):\n",
        "    batch = tuple(t.to(device) for t in batch)\n",
        "    b_input_ids, b_input_mask, b_segs,b_labels = batch  \n",
        "    with torch.no_grad():\n",
        "      outputs = model(input_ids =b_input_ids,token_type_ids=b_segs, input_mask = b_input_mask,labels=b_labels)\n",
        "      tmp_eval_loss, logits = outputs[:2]\n",
        "    \n",
        "    # Get textclassification predict result\n",
        "    logits = logits.detach().cpu().numpy()\n",
        "    label_ids = b_labels.to('cpu').numpy()\n",
        "    tmp_eval_accuracy = accuracy(logits, label_ids)\n",
        "  \n",
        "    # Save predict and real label reuslt for analyze\n",
        "    for predict in np.argmax(logits, axis=1):\n",
        "      y_predict.append(predict)\n",
        "  \n",
        "    for real_result in label_ids.tolist():\n",
        "      y_true.append(real_result)\n",
        "\n",
        "    \n",
        "    eval_loss += tmp_eval_loss.mean().item()\n",
        "    eval_accuracy += tmp_eval_accuracy\n",
        "   \n",
        "    nb_eval_steps += 1\n",
        "    \n",
        "    \n",
        "  eval_loss = eval_loss / nb_eval_steps\n",
        "  eval_accuracy = eval_accuracy / len(val_inputs)\n",
        "  loss = tr_loss/nb_tr_steps \n",
        "  result = {'eval_loss': eval_loss,\n",
        "                  'eval_accuracy': eval_accuracy,\n",
        "                  'loss': loss}\n",
        "  report = classification_report(y_pred=np.array(y_predict),y_true=np.array(y_true))\n",
        "  print(report)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Eq2R4xk6DsRx",
        "outputId": "061d03c2-ab70-4853-f5b8-e2197c2f54d7"
      },
      "source": [
        "predict(valid_dataloader)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.89      0.91      0.90       877\n",
            "           1       0.68      0.75      0.71       139\n",
            "           2       0.85      0.75      0.80       267\n",
            "\n",
            "    accuracy                           0.86      1283\n",
            "   macro avg       0.81      0.80      0.80      1283\n",
            "weighted avg       0.86      0.86      0.86      1283\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "obl-rzuuD97x"
      },
      "source": [
        "#test on new dataset\n",
        "test_sentences = test.Tweets.to_list()\n",
        "test_labels = test.Label.to_list()\n",
        "# Make label into id\n",
        "test_tags = [tag2idx[str(lab)] for lab in test_labels]\n",
        "\n",
        "#input_ids, input_mask, segment_ids\n",
        "test_input_ids = []\n",
        "test_input_masks = []\n",
        "test_segment_ids = []\n",
        "\n",
        "SEG_ID_A   = 0\n",
        "SEG_ID_B   = 1\n",
        "SEG_ID_CLS = 2\n",
        "SEG_ID_SEP = 3\n",
        "SEG_ID_PAD = 4\n",
        "\n",
        "UNK_ID = tokenizer.encode(\"<unk>\")[0]\n",
        "CLS_ID = tokenizer.encode(\"<cls>\")[0]\n",
        "SEP_ID = tokenizer.encode(\"<sep>\")[0]\n",
        "MASK_ID = tokenizer.encode(\"<mask>\")[0]\n",
        "EOD_ID = tokenizer.encode(\"<eod>\")[0]\n",
        "\n",
        "for i,sentence in enumerate(test_sentences):\n",
        "    # Tokenize sentence to token id list\n",
        "    tokens_a = tokenizer.encode(sentence)\n",
        "    \n",
        "    # Trim the len of text\n",
        "    if(len(tokens_a)>max_len-2):\n",
        "        tokens_a = tokens_a[:max_len-2]\n",
        "        \n",
        "        \n",
        "    tokens = []\n",
        "    segment_ids = []\n",
        "    \n",
        "    for token in tokens_a:\n",
        "        tokens.append(token)\n",
        "        segment_ids.append(SEG_ID_A)\n",
        "        \n",
        "    # Add <sep> token \n",
        "    tokens.append(SEP_ID)\n",
        "    segment_ids.append(SEG_ID_A)\n",
        "    \n",
        "    \n",
        "    # Add <cls> token\n",
        "    tokens.append(CLS_ID)\n",
        "    segment_ids.append(SEG_ID_CLS)\n",
        "    \n",
        "    input_ids = tokens\n",
        "    \n",
        "    # The mask has 0 for real tokens and 1 for padding tokens. Only real\n",
        "    # tokens are attended to.\n",
        "    input_mask = [0] * len(input_ids)\n",
        "\n",
        "    # Zero-pad up to the sequence length at fornt\n",
        "    if len(input_ids) < max_len:\n",
        "        delta_len = max_len - len(input_ids)\n",
        "        input_ids = [0] * delta_len + input_ids\n",
        "        input_mask = [1] * delta_len + input_mask\n",
        "        segment_ids = [SEG_ID_PAD] * delta_len + segment_ids\n",
        "\n",
        "    assert len(input_ids) == max_len\n",
        "    assert len(input_mask) == max_len\n",
        "    assert len(segment_ids) == max_len\n",
        "    \n",
        "    test_input_ids.append(input_ids)\n",
        "    test_input_masks.append(input_mask)\n",
        "    test_segment_ids.append(segment_ids)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aQow0QT1FUk4"
      },
      "source": [
        "#convert to tensor\n",
        "test_input_ids = torch.tensor(test_input_ids)\n",
        "test_input_masks = torch.tensor(test_input_masks)\n",
        "test_segment_ids = torch.tensor(test_segment_ids)\n",
        "test_tags = torch.tensor(test_tags)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "im5_i-S4F2sz"
      },
      "source": [
        "test_data = TensorDataset(test_input_ids, test_input_masks,test_segment_ids, test_tags)\n",
        "test_sampler = SequentialSampler(test_data)\n",
        "test_dataloader = DataLoader(test_data, sampler=test_sampler, batch_size=batch_num)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W_k8cm-jGY_o",
        "outputId": "b03b782b-3d21-465b-e093-6e2b8dd352ea"
      },
      "source": [
        "predict(test_dataloader)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.88      0.87      2186\n",
            "           1       0.97      0.75      0.85       387\n",
            "           2       0.60      0.61      0.61       633\n",
            "\n",
            "    accuracy                           0.81      3206\n",
            "   macro avg       0.81      0.75      0.77      3206\n",
            "weighted avg       0.82      0.81      0.81      3206\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "epb0LkYAY8FJ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}